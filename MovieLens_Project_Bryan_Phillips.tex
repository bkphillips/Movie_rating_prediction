\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={MovieLens Project},
            pdfauthor={Bryan Phillips},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{MovieLens Project}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Bryan Phillips}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{1/6/2020}


\begin{document}
\maketitle

\subsection{Overview}\label{overview}

For this project, the task is to create a movie recommendation system
using movie ratings data given on a scale from 1-5 from individual users
in order to predict user ratings of other movies they have not yet
rated.

The data I am using is the 10 million user ratings MovieLens data
available at the link below:
``\url{https://grouplens.org/datasets/movielens/10m/}''

The information given in this dataset includes: -User ID -Movie Title
-Movie ID -Time Stamp -Genre -Rating

Below is a sample of the data given:

\begin{verbatim}
##   userId movieId rating timestamp                         title
## 1      1     122      5 838985046              Boomerang (1992)
## 2      1     185      5 838983525               Net, The (1995)
## 4      1     292      5 838983421               Outbreak (1995)
## 5      1     316      5 838983392               Stargate (1994)
## 6      1     329      5 838983392 Star Trek: Generations (1994)
## 7      1     355      5 838984474       Flintstones, The (1994)
##                          genres
## 1                Comedy|Romance
## 2         Action|Crime|Thriller
## 4  Action|Drama|Sci-Fi|Thriller
## 5       Action|Adventure|Sci-Fi
## 6 Action|Adventure|Drama|Sci-Fi
## 7       Children|Comedy|Fantasy
\end{verbatim}

The datasets have already been split into a testing and validation
datasets. The testing dataset has 9,000,055 observations from users. The
validation dataset has 999,999 observations.

The analysis I plan on using is based off of the recommendation system
section of the machine learning course part of the Harvard Data Science
Certificate Course. In this section, a matrix factorization model was
used to build a recommendation system. I plan on building off of this
original analysis.

The method in which I am testing the validity of my recommendation is by
seeing the Root Mean Squared Error (RMSE) of each model on the
validation dataset provided. My goal is to get a RMSE of less than
0.8649.

note: The datasets used in this analysis were provided on the group
forum DropBox folder because the datasets generated from the given
dataset code did not match the grader results. For consistency, I used
the given datasets throughout the analysis.

Below is a link to the dropbox folder of the datasets I used and
reference in my code
\url{https://www.dropbox.com/sh/n2d1gji7kkdsvhi/AADnvvXmRqXOfoP7bHN_1ydda?dl=0}

All the code used for this analysis is available on my GitHub repository
linked below:
\url{https://github.com/bkphillips/Movie_rating_prediction/}

\subsection{Analysis}\label{analysis}

For this analysis, I build off the original recommendation system
analysis previously mentioned in the machine learning course.

The first model looks just at the overall average of the test dataset,
which is 3.512465. This naive model has a RMSE of 1.0603.

The second model is based off the observation that each individual movie
has an effect on the rating. This movie effect is represented by
``b\_i'' in the second movel. Below is a distribution of this effect:

\includegraphics{MovieLens_Project_Bryan_Phillips_files/figure-latex/movie avg-1.pdf}

The third model is based off of the observation that there is a user
bias that affects the ratings. Some users may be very picky, while
others are very generous in their ratings of movies. Below is a
distribution of user ratings:
\includegraphics{MovieLens_Project_Bryan_Phillips_files/figure-latex/user ratings-1.pdf}

The third model combines both the movie and user effects as b\_i + b\_u.

In my own analysis, I wanted to incorporate the genre into the model in
order to get a more accurate recommendation. In order to do this, I
converted the genre information into a tidy format in order to provide a
more accurate recommendation. Before converting the genre, there were
797 distinct categories for genre show in the average rating
distribution below:
\includegraphics{MovieLens_Project_Bryan_Phillips_files/figure-latex/non tidy genre-1.pdf}

I then converted the data into a long format where I now have only 20
different genres that can more accurately predict the rating, as shown
by the plot below of the average rating by the new tidy genres:
\includegraphics{MovieLens_Project_Bryan_Phillips_files/figure-latex/tidy genre-1.pdf}

For the fourth model, I used this genre effect (b\_g) seen in the figure
above alongise both the movie and user effect represented as ``b\_i +
b\_u + b\_g''.

For a fifth model, I made an assumption that each user most likely has a
strong preference for a genre that will affect the rating, which would
help make a strong prediction. I represent is user genre effect as b\_ug
in a model that incorporates also the movie and user effects as ``b\_i +
b\_u + b\_ug''.

When validating this last model on the validation data, I noticed that
there is not always User Genre rating information for each user in the
new dataset, which in that case the model assumes just the movie and
user effects.

\subsection{Results}\label{results}

Below are my RMSE results from the test data on each model I previously
described above:

\begin{longtable}[]{@{}lr@{}}
\toprule
method & RMSE\tabularnewline
\midrule
\endhead
Just the average & 1.0603313\tabularnewline
Movie Effect Model & 0.9423475\tabularnewline
Movie + User Effects Model & 0.8567039\tabularnewline
Movie + User Effects + Genre Effects Model & 0.8565891\tabularnewline
Movie + User Effects + User Genre Effects Model &
0.8097699\tabularnewline
\bottomrule
\end{longtable}

It appears that the last model that incorporated the user-genre effects
had an significant improvement on the RMSE on the testing data.

For validation, I only looked at the last three models on the validation
dataset. Below are the results of validating these three models using
the validation dataset:

\begin{longtable}[]{@{}lr@{}}
\toprule
method & RMSE\tabularnewline
\midrule
\endhead
Movie + User Effects Model & 0.8653488\tabularnewline
Movie + User Effects + Genre Effects Model & 0.8652323\tabularnewline
Movie + User Effects + User Genre Effects Model &
0.8497552\tabularnewline
\bottomrule
\end{longtable}

\subsection{Conclusion}\label{conclusion}

It appears that the fifth model of Movie, User, and User Genre Effects
(b\_i + b\_u + b\_ug) had the strongest predictive performance on the
validation dataset with a RMSE of 0.8497552. It is interesting that
addition of the genre effects on the model did not cause much predictive
improvement on the model.

The results of this analysis show that individual tastes for a particual
genre have a significant impact on their rating for a particular movie.
In the real world, this makes sense given that many people have a strong
affinity towards a particular genre of movies.

A major limitation of this method is that it requires previous user
information and would not have much predictive performance on users that
had not already provided rating information into the model.


\end{document}
